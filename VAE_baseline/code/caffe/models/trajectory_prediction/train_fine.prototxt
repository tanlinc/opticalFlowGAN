<%page args="batch_sz, my_loss_wt=1.0, genmode=False, pat_sz=28"/>
<%!
  import math
%>

<%def name="zs(pfx,num_output,out_shp,my_loss_wt,input='',decay=1)">
  % if not genmode:
    layer {
      name: "${pfx}mu"
      type: "Convolution"
      bottom: "${input}"
      top: "${pfx}mu"
      param {
        lr_mult: 1
        decay_mult: ${decay}
      }
      param {
        lr_mult: 2
        decay_mult: 0
      }
      convolution_param {
        num_output: ${num_output}
        kernel_size: 1
        stride: 1
        pad: 0
        weight_filler {
          type: "gaussian"
          std: .0001
        }
        bias_filler {
          type: "constant"
          value: 0
        }
      }
    }

layer {
  name: "${pfx}poolmu"
  type: "Pooling"
  bottom: "${pfx}mu"
  top: "${pfx}poolmu"
  pooling_param {
    pool: AVE
    kernel_size: 20
    stride: 20
    pad: 0
  }
}

    layer {
      name: "${pfx}logsd"
      type: "Convolution"
      bottom: "${input}"
      top: "${pfx}logsd"
      param {
        lr_mult: .1
        decay_mult: 1
      }
      param {
        lr_mult: .2
        decay_mult: 0
      }
      convolution_param {
        num_output: ${num_output}
        kernel_size: 1
        stride: 1
        pad: 0
        weight_filler {
          type: "gaussian"
          std: .0001
        }
        bias_filler {
          type: "constant"
          value: 0
        }
      }
    }

layer {
  name: "${pfx}poollogsd"
  type: "Pooling"
  bottom: "${pfx}logsd"
  top: "${pfx}poollogsd"
  pooling_param {
    pool: AVE
    kernel_size: 20
    stride: 20
    pad: 0
  }
}

    layer{
      name: "${pfx}poolsd"
      type: "Exp"
      bottom: "${pfx}poollogsd"
      top: "${pfx}poolsd"
    }
    layer{
      name: "${pfx}var"
      type: "Eltwise"
      bottom: "${pfx}poolsd"
      bottom: "${pfx}poolsd"
      top: "${pfx}var"
      eltwise_param{
        operation: PROD
      }
    }
    layer{
      name: "${pfx}meansq"
      type: "Eltwise"
      bottom: "${pfx}poolmu"
      bottom: "${pfx}poolmu"
      top: "${pfx}meansq"
      eltwise_param{
        operation: PROD
      }
    }
    layer{
      name: "${pfx}kldiv"
      type: "Eltwise"
      bottom: "${pfx}meansq"
      bottom: "${pfx}var"
      bottom: "${pfx}poollogsd"
      top: "${pfx}kldiv"
      eltwise_param{
        operation: SUM
        coeff: 0.5
        coeff: 0.5
        coeff: -1.0
      }
    }
    layer{
      name: "${pfx}loss"
      type: "Reduction"
      bottom: "${pfx}kldiv"
      top: "${pfx}loss"
      loss_weight: ${my_loss_wt/batch_sz}
    }
  % else:
    layer{
      name: "${pfx}mu"
      type: "DummyData"
      top: "${pfx}mu"
      dummy_data_param{
        num: ${batch_sz}
        channels: ${num_output}
        height: ${out_shp}
        width: ${out_shp}
        data_filler{
          type: "constant"
          value: 0
        }
      }
    }
    layer{
      name: "${pfx}sd"
      type: "DummyData"
      top: "${pfx}sd"
      dummy_data_param{
        num: ${batch_sz}
        channels: ${num_output}
        height: ${out_shp}
        width: ${out_shp}
        data_filler{
          type: "constant"
          value: 1
        }
      }
    }
  % endif
  layer{
    name: "${pfx}noise"
    type: "DummyData"
    top: "${pfx}noise"
    dummy_data_param{
      num: ${batch_sz}
      channels: ${num_output}
      height: 1
      width: 1
      data_filler{
        type: "gaussian"
        std: 1.
      }
    }
  }
  layer{
    name: "${pfx}sdnoise"
    type: "Eltwise"
    bottom: "${pfx}noise"
    bottom: "${pfx}poolsd"
    top: "${pfx}sdnoise"
    eltwise_param{
      operation: PROD
    }
  }
  layer{
    name: "${pfx}sample"
    type: "Eltwise"
    bottom: "${pfx}poolmu"
    bottom: "${pfx}sdnoise"
    top: "${pfx}sample"
    eltwise_param{
      operation: SUM
    }
  }
</%def>


<%def name="image_tower(pfx,input, sdev)">

layer {
  name: "${pfx}conv1"
  type: "Convolution"
  bottom: "${input}"
  top: "${pfx}conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    pad: 4
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm1"
  type: "BatchNorm"
  bottom: "${pfx}conv1"
  top: "${pfx}conv1"
}

layer {
  name: "${pfx}relu1"
  type: "ReLU"
  bottom: "${pfx}conv1"
  top: "${pfx}conv1"
}
layer {
  name: "${pfx}norm1"
  type: "LRN"
  bottom: "${pfx}conv1"
  top: "${pfx}norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "${pfx}pool1"
  type: "Pooling"
  bottom: "${pfx}norm1"
  top: "${pfx}pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "${pfx}conv2"
  type: "Convolution"
  bottom: "${pfx}pool1"
  top: "${pfx}conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm2"
  type: "BatchNorm"
  bottom: "${pfx}conv2"
  top: "${pfx}conv2"
}

layer {
  name: "${pfx}relu2"
  type: "ReLU"
  bottom: "${pfx}conv2"
  top: "${pfx}conv2"
}
layer {
  name: "${pfx}norm2"
  type: "LRN"
  bottom: "${pfx}conv2"
  top: "${pfx}norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "${pfx}pool2"
  type: "Pooling"
  bottom: "${pfx}norm2"
  top: "${pfx}pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "${pfx}conv3"
  type: "Convolution"
  bottom: "${pfx}pool2"
  top: "${pfx}conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm3"
  type: "BatchNorm"
  bottom: "${pfx}conv3"
  top: "${pfx}conv3"
}

layer {
  name: "${pfx}relu3"
  type: "ReLU"
  bottom: "${pfx}conv3"
  top: "${pfx}conv3"
}
layer {
  name: "${pfx}conv4"
  type: "Convolution"
  bottom: "${pfx}conv3"
  top: "${pfx}conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm4"
  type: "BatchNorm"
  bottom: "${pfx}conv4"
  top: "${pfx}conv4"
}

layer {
  name: "${pfx}relu4"
  type: "ReLU"
  bottom: "${pfx}conv4"
  top: "${pfx}conv4"
}
layer {
  name: "${pfx}conv5"
  type: "Convolution"
  bottom: "${pfx}conv4"
  top: "${pfx}conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm5"
  type: "BatchNorm"
  bottom: "${pfx}conv5"
  top: "${pfx}conv5"
}

layer {
  name: "${pfx}relu5"
  type: "ReLU"
  bottom: "${pfx}conv5"
  top: "${pfx}conv5"
}
layer {
  name: "${pfx}conv6"
  type: "Convolution"
  bottom: "${pfx}conv5"
  top: "${pfx}conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm6"
  type: "BatchNorm"
  bottom: "${pfx}conv6"
  top: "${pfx}conv6"
}

layer {
  name: "${pfx}relu6"
  type: "ReLU"
  bottom: "${pfx}conv6"
  top: "${pfx}conv6"
}

layer {
  name: "${pfx}conv7"
  type: "Convolution"
  bottom: "${pfx}conv6"
  top: "${pfx}conv7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm7"
  type: "BatchNorm"
  bottom: "${pfx}conv7"
  top: "${pfx}conv7"
}

layer {
  name: "${pfx}relu7"
  type: "ReLU"
  bottom: "${pfx}conv7"
  top: "${pfx}conv7"
}

layer {
  name: "${pfx}conv8"
  type: "Convolution"
  bottom: "${pfx}conv7"
  top: "${pfx}conv8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm8"
  type: "BatchNorm"
  bottom: "${pfx}conv8"
  top: "${pfx}conv8"
}

layer {
  name: "${pfx}relu8"
  type: "ReLU"
  bottom: "${pfx}conv8"
  top: "${pfx}conv8"
}

layer {
  name: "${pfx}conv9"
  type: "Convolution"
  bottom: "${pfx}conv8"
  top: "${pfx}conv9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm9"
  type: "BatchNorm"
  bottom: "${pfx}conv9"
  top: "${pfx}conv9"
}

layer {
  name: "${pfx}relu9"
  type: "ReLU"
  bottom: "${pfx}conv9"
  top: "${pfx}conv9"
}

layer {
  name: "${pfx}conv10"
  type: "Convolution"
  bottom: "${pfx}conv9"
  top: "${pfx}conv10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm10"
  type: "BatchNorm"
  bottom: "${pfx}conv10"
  top: "${pfx}conv10"
}

layer {
  name: "${pfx}relu10"
  type: "ReLU"
  bottom: "${pfx}conv10"
  top: "${pfx}conv10"
}

layer {
  name: "${pfx}conv11"
  type: "Convolution"
  bottom: "${pfx}conv10"
  top: "${pfx}conv11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm11"
  type: "BatchNorm"
  bottom: "${pfx}conv11"
  top: "${pfx}conv11"
}

layer {
  name: "${pfx}relu11"
  type: "ReLU"
  bottom: "${pfx}conv11"
  top: "${pfx}conv11"
}

layer {
  name: "${pfx}conv12"
  type: "Convolution"
  bottom: "${pfx}conv11"
  top: "${pfx}conv12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm12"
  type: "BatchNorm"
  bottom: "${pfx}conv12"
  top: "${pfx}conv12"
}

layer {
  name: "${pfx}relu12"
  type: "ReLU"
  bottom: "${pfx}conv12"
  top: "${pfx}conv12"
}


layer {
  name: "${pfx}conv13"
  type: "Convolution"
  bottom: "${pfx}conv12"
  top: "${pfx}conv13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm13"
  type: "BatchNorm"
  bottom: "${pfx}conv13"
  top: "${pfx}conv13"
}


layer {
  name: "${pfx}relu13"
  type: "ReLU"
  bottom: "${pfx}conv13"
  top: "${pfx}conv13"
}

layer {
  name: "${pfx}conv14"
  type: "Convolution"
  bottom: "${pfx}conv13"
  top: "${pfx}conv14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm14"
  type: "BatchNorm"
  bottom: "${pfx}conv14"
  top: "${pfx}conv14"
}


layer {
  name: "${pfx}relu14"
  type: "ReLU"
  bottom: "${pfx}conv14"
  top: "${pfx}conv14"
}



</%def>

<%def name="cascade_super_short(pfx,input_first, input_second, C, factor, down_factor, loss_weight, std, mult, recept, thepad)">

layer{
  name: "${pfx}deconv"
  type: "Deconvolution"
  bottom: "${input_first}"
  top: "${pfx}deconv"
  convolution_param {
  num_output: ${C}
  group: ${C}
  kernel_size: ${(2 * factor - factor % 2)}
  stride: ${factor}
  pad: ${int(math.ceil((factor -1 ) / 2.0))}
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: ${1 * mult}
    decay_mult: ${1 * mult}
  }
  param {
    lr_mult: ${2 * mult}
    decay_mult: 0
  }
}

layer{
  name: "${pfx}convcat"
  type: "Concat"
  bottom: "${pfx}deconv"
  bottom: "${input_second}"
  top: "${pfx}convcat"
  concat_param{
    axis: 1
  }
}

layer{
  name: "${pfx}reconst"
  type: "Convolution"
  bottom: "${pfx}convcat"
  top: "${pfx}reconst"

  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    pad: 1
        weight_filler {
          type: "xavier"
          std: ${std}
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: ${1 * mult}
    decay_mult: ${1 * mult}
  }
  param {
    lr_mult: ${2 * mult}
    decay_mult: 0
  }
}

layer {
  name: "${pfx}rawpooldata"
  type: "Pooling"
  bottom: "rawtrajdata"
  top: "${pfx}rawpooldata"
  pooling_param {
    pool: AVE
    kernel_size: ${down_factor}
    stride: ${down_factor}
  }
}

layer{
  name: "${pfx}poolnorm"
  type: "Deconvolution"
  bottom: "avgsampletall"
  top: "${pfx}poolnorm"
  convolution_param {
  num_output: 10
  group: 2
  kernel_size: ${32}
  stride: ${16}
  pad: ${8}
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}

layer {
  name: "${pfx}poolpower"
  type: "Power"
  bottom: "${pfx}poolnorm"
  top: "${pfx}poolpower"
  power_param {
   power: -1.0
  }
}

layer {
  name: "${pfx}pooldata"
  type: "Eltwise"
  bottom: "${pfx}rawpooldata"
  bottom: "${pfx}poolpower"
  top: "${pfx}pooldata"
  eltwise_param {
    operation: PROD
  }
}


  layer {
    name: "${pfx}reconstloss"
    type: "EuclideanLoss"
    bottom: "${pfx}reconst"
    bottom: "${pfx}pooldata"
    top: "${pfx}reconstloss"
    loss_weight: ${loss_weight}
  }

</%def>

<%def name="cascade_short(pfx,input_first, input_second, C, factor, down_factor, loss_weight, std, mult, recept, thepad)">

layer{
  name: "${pfx}convcat"
  type: "Concat"
  bottom: "${input_first}"
  bottom: "${input_second}"
  top: "${pfx}convcat"
  concat_param{
    axis: 1
  }
}

layer{
  name: "${pfx}deconv"
  type: "Deconvolution"
  bottom: "${pfx}convcat"
  top: "${pfx}deconv"
  convolution_param {
  num_output: 640
  group: 640
  kernel_size: ${(2 * factor - factor % 2)}
  stride: ${factor}
  pad: ${int(math.ceil((factor -1 ) / 2.0))}
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: ${1 * mult}
    decay_mult: ${1 * mult}
  }
  param {
    lr_mult: ${2 * mult}
    decay_mult: 0
  }
}

layer{
  name: "${pfx}reconst_inter_one"
  type: "Convolution"
  bottom: "${pfx}deconv"
  top: "${pfx}reconst_inter_one"

  convolution_param {
    num_output: ${C}
    kernel_size: ${recept}
    stride: 1
    pad: ${thepad}
        weight_filler {
          type: "xavier"
          std: ${std}
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: ${1 * mult}
    decay_mult: ${1 * mult}
  }
  param {
    lr_mult: ${2 * mult}
    decay_mult: 0
  }
}

layer{
  name: "${pfx}reconst"
  type: "Convolution"
  bottom: "${pfx}reconst_inter_one"
  top: "${pfx}reconst"

  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    pad: 1
        weight_filler {
          type: "xavier"
          std: ${std}
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: ${1 * mult}
    decay_mult: ${1 * mult}
  }
  param {
    lr_mult: ${2 * mult}
    decay_mult: 0
  }
}

layer {
  name: "${pfx}rawpooldata"
  type: "Pooling"
  bottom: "rawtrajdata"
  top: "${pfx}rawpooldata"
  pooling_param {
    pool: AVE
    kernel_size: ${down_factor}
    stride: ${down_factor}
  }
}

layer{
  name: "${pfx}poolnorm"
  type: "Deconvolution"
  bottom: "avgsampletall"
  top: "${pfx}poolnorm"
  convolution_param {
  num_output: 10
  group: 2
  kernel_size: ${16}
  stride: ${8}
  pad: ${4}
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}

layer {
  name: "${pfx}poolpower"
  type: "Power"
  bottom: "${pfx}poolnorm"
  top: "${pfx}poolpower"
  power_param {
   power: -1.0
  }
}

layer {
  name: "${pfx}pooldata"
  type: "Eltwise"
  bottom: "${pfx}rawpooldata"
  bottom: "${pfx}poolpower"
  top: "${pfx}pooldata"
  eltwise_param {
    operation: PROD
  }
}


  layer {
    name: "${pfx}reconstloss"
    type: "EuclideanLoss"
    bottom: "${pfx}reconst"
    bottom: "${pfx}pooldata"
    top: "${pfx}reconstloss"
    loss_weight: ${loss_weight}
  }


</%def>

<%def name="enc_tower(pfx,input, sdev)">
layer {
  name: "${pfx}conv1"
  type: "Convolution"
  bottom: "${input}"
  top: "${pfx}conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    pad: 4
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm1"
  type: "BatchNorm"
  bottom: "${pfx}conv1"
  top: "${pfx}conv1"
}

layer {
  name: "${pfx}relu1"
  type: "ReLU"
  bottom: "${pfx}conv1"
  top: "${pfx}conv1"
}
layer {
  name: "${pfx}norm1"
  type: "LRN"
  bottom: "${pfx}conv1"
  top: "${pfx}norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "${pfx}pool1"
  type: "Pooling"
  bottom: "${pfx}norm1"
  top: "${pfx}pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "${pfx}conv2"
  type: "Convolution"
  bottom: "${pfx}pool1"
  top: "${pfx}conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm2"
  type: "BatchNorm"
  bottom: "${pfx}conv2"
  top: "${pfx}conv2"
}

layer {
  name: "${pfx}relu2"
  type: "ReLU"
  bottom: "${pfx}conv2"
  top: "${pfx}conv2"
}
layer {
  name: "${pfx}norm2"
  type: "LRN"
  bottom: "${pfx}conv2"
  top: "${pfx}norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "${pfx}pool2"
  type: "Pooling"
  bottom: "${pfx}norm2"
  top: "${pfx}pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "${pfx}conv3"
  type: "Convolution"
  bottom: "${pfx}pool2"
  top: "${pfx}conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm3"
  type: "BatchNorm"
  bottom: "${pfx}conv3"
  top: "${pfx}conv3"
}

layer {
  name: "${pfx}relu3"
  type: "ReLU"
  bottom: "${pfx}conv3"
  top: "${pfx}conv3"
}
layer {
  name: "${pfx}conv4"
  type: "Convolution"
  bottom: "${pfx}conv3"
  top: "${pfx}conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm4"
  type: "BatchNorm"
  bottom: "${pfx}conv4"
  top: "${pfx}conv4"
}

layer {
  name: "${pfx}relu4"
  type: "ReLU"
  bottom: "${pfx}conv4"
  top: "${pfx}conv4"
}
layer {
  name: "${pfx}conv5"
  type: "Convolution"
  bottom: "${pfx}conv4"
  top: "${pfx}conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
        weight_filler {
          type: "xavier"
          std: ${sdev}
        }
  }
}

layer { 
  name: "${pfx}batchnorm5"
  type: "BatchNorm"
  bottom: "${pfx}conv5"
  top: "${pfx}conv5"
}

layer {
  name: "${pfx}relu5"
  type: "ReLU"
  bottom: "${pfx}conv5"
  top: "${pfx}conv5"
}
</%def>

  layer {
    name: "imdata"
    top: "imdata"
    type: "DummyData"
      dummy_data_param{
        num: ${batch_sz}
        channels: 3
        height: 256
        width: 320
        data_filler{
          type: "constant"
          value: 0
        }
   }
  }

layer {
  name: "rawtrajdata"
  top: "rawtrajdata"
  type: "DummyData"
      dummy_data_param{
        num: ${batch_sz}
        channels: 10
        height: 64
        width: 80
        data_filler{
          type: "constant"
          value: 0
        }
   }
}

layer {
  name: "rawpooldata"
  type: "Pooling"
  bottom: "rawtrajdata"
  top: "rawpooldata"
  pooling_param {
    pool: AVE
    kernel_size: 4
    stride: 4
  }
}

  layer {
    name: "SlicedTraj"
    type: "Slice"
    bottom: "rawpooldata"
    top: "xdata"
    top: "ydata"
    slice_param {
       axis: 1
       slice_point: 5
    }
  }

layer {
  name: "axdata"
  type: "Eltwise"
  bottom: "xdata"
  bottom: "xdata"
  top: "axdata"
  eltwise_param {
    operation: PROD
  }
}

layer{
  name: "xsum"
  type: "Convolution"
  bottom: "axdata"
  top: "xsum"

  convolution_param {
    num_output: 1
    kernel_size: 1
    stride: 1
    pad: 0
        weight_filler {
          type: "constant"
          value: 1.0
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult:0
    decay_mult: 0
  }
}

  layer {
    name: "xsumsquare"
    type: "Power"
    bottom: "xsum"
    top: "xsumsquare"
      power_param{
        power: 0.5
        scale: 0.033
        shift: 0.0000000000000001
      }
  }


layer {
  name: "avgx"
  type: "Pooling"
  bottom: "xsumsquare"
  top: "avgx"
  pooling_param {
    pool: AVE
    kernel_size: 20
    stride: 20
    pad: 0
  }
}

layer {
  name: "aydata"
  type: "Eltwise"
  bottom: "ydata"
  bottom: "ydata"
  top: "aydata"
  eltwise_param {
    operation: PROD
  }
}

layer{
  name: "ysum"
  type: "Convolution"
  bottom: "aydata"
  top: "ysum"

  convolution_param {
    num_output: 1
    kernel_size: 1
    stride: 1
    pad: 0
        weight_filler {
          type: "constant"
          value: 1.0
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult:0
    decay_mult: 0
  }
}

  layer {
    name: "ysumsquare"
    type: "Power"
    bottom: "ysum"
    top: "ysumsquare"
      power_param{
        power: 0.5
        scale: 0.033
        shift: 0.0000000000000001
      }
  }


layer {
  name: "avgy"
  type: "Pooling"
  bottom: "ysumsquare"
  top: "avgy"
  pooling_param {
    pool: AVE
    kernel_size: 20
    stride: 20
    pad: 0
  }
}

layer{
  name: "avgsample"
  type: "Concat"
  bottom: "avgx"
  bottom: "avgy"
  top: "avgsample"
  concat_param{
    axis: 1
  }
}

layer{
  name: "avgsample_reshape"
  type: "Reshape"
  bottom: "avgsample"
  top: "avgsample_reshape"
  reshape_param{
   shape {
    dim: 0
    dim: 0
    dim: -1
}
  }
}


layer{
  name: "avgsamplewide"
  type: "Concat"
  bottom: "avgsample_reshape"
  bottom: "avgsample_reshape"
  bottom: "avgsample_reshape"
  bottom: "avgsample_reshape"
  top: "avgsamplewide"
  concat_param{
    axis: 2
  }
}

layer{
  name: "avgsamplewide_reshape"
  type: "Reshape"
  bottom: "avgsamplewide"
  top: "avgsamplewide_reshape"
  reshape_param{
   shape {
    dim: 0
    dim: 0
    dim: 0
    dim: -1
}
  }
}


layer{
  name: "avgsampletall"
  type: "Concat"
  bottom: "avgsamplewide_reshape"
  bottom: "avgsamplewide_reshape"
  bottom: "avgsamplewide_reshape"
  bottom: "avgsamplewide_reshape"
  bottom: "avgsamplewide_reshape"
  top: "avgsampletall"
  concat_param{
    axis: 3
  }
}

layer{
  name: "trajnorm"
  type: "Deconvolution"
  bottom: "avgsampletall"
  top: "trajnorm"
  convolution_param {
  num_output: 10
  group: 2
  kernel_size: 8
  stride: 4
  pad: 2
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}

layer {
  name: "trajpower"
  type: "Power"
  bottom: "trajnorm"
  top: "trajpower"
  power_param {
   power: -1.0
  }
}

layer {
  name: "normtrajdata"
  type: "Eltwise"
  bottom: "rawpooldata"
  bottom: "trajpower"
  top: "normtrajdata"
  eltwise_param {
    operation: PROD
  }
}

${image_tower("image","imdata", 0.01)}

layer{
  name: "encinput_mag"
   type: "Concat"
   bottom: "trajnorm"
   bottom: "imageconv12"
   top: "encinput_mag"
   concat_param{
   axis: 1
  }
}

layer{
  name: "encinput_traj"
  type: "Concat"
  bottom: "normtrajdata"
  bottom: "imageconv12"
  top: "encinput_traj"
  concat_param{
   axis: 1
  }
}

${enc_tower("traj","encinput_traj", 0.001)}

${zs("themagz",2,2,25.0,"encinput_mag",decay=0)}
${zs("thez",8,8,25.0,"trajconv5",decay=0)}

layer{
  name: "thezsamplewide"
  type: "Concat"
  bottom: "thezsample"
  bottom: "thezsample"
  bottom: "thezsample"
  bottom: "thezsample"
  top: "thezsamplewide"
  concat_param{
    axis: 2
  }
}

layer{
  name: "thezsampletall"
  type: "Concat"
  bottom: "thezsamplewide"
  bottom: "thezsamplewide"
  bottom: "thezsamplewide"
  bottom: "thezsamplewide"
  bottom: "thezsamplewide"
  top: "thezsampletall"
  concat_param{
    axis: 3
  }
}

layer {
  name: "imoffset"
  type: "Convolution"
  bottom: "imageconv14"
  top: "imoffset"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 4
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "imoffsetnorm"
  type: "BatchNorm"
  bottom: "imoffset"
  top: "imoffset"
}


layer {
  name: "imoffsetrelu"
  type: "ReLU"
  bottom: "imoffset"
  top: "imoffset"
}

layer{
  name: "zoffset"
  type: "Eltwise"
  bottom: "thezsampletall"
  bottom: "imoffset"
  top: "zoffset"
  eltwise_param{
    operation: SUM
  }
}


layer{
  name: "zdeconv"
  type: "Deconvolution"
  bottom: "zoffset"
  top: "zdeconv"
  convolution_param {
  num_output: 256
  group: 8
  kernel_size: 8
  stride: 4
  pad: 2
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}


layer{
  name: "themagzsamplewide"
  type: "Concat"
  bottom: "themagzsample"
  bottom: "themagzsample"
  bottom: "themagzsample"
  bottom: "themagzsample"
  top: "themagzsamplewide"
  concat_param{
    axis: 2
  }
}

layer{
  name: "themagzsampletall"
  type: "Concat"
  bottom: "themagzsamplewide"
  bottom: "themagzsamplewide"
  bottom: "themagzsamplewide"
  bottom: "themagzsamplewide"
  bottom: "themagzsamplewide"
  top: "themagzsampletall"
  concat_param{
    axis: 3
  }
}

layer {
  name: "imoffset_mag"
  type: "Convolution"
  bottom: "imageconv14"
  top: "imoffset_mag"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    stride: 4
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "imoffsetnorm_mag"
  type: "BatchNorm"
  bottom: "imoffset_mag"
  top: "imoffset_mag"
}


layer {
  name: "imoffsetrelu_mag"
  type: "ReLU"
  bottom: "imoffset_mag"
  top: "imoffset_mag"
}

layer{
  name: "magoffset"
  type: "Eltwise"
  bottom: "themagzsampletall"
  bottom: "imoffset_mag"
  top: "magoffset"
  eltwise_param{
    operation: SUM
  }
}

layer{
  name: "magzdeconv"
  type: "Deconvolution"
  bottom: "magoffset"
  top: "magzdeconv"
  convolution_param {
  num_output: 256
  group: 2
  kernel_size: 8
  stride: 4
  pad: 2
        weight_filler {
          type: "bilinear"
        }
}
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}

layer{
  name: "cond_pred_traj"
  type: "Eltwise"
  bottom: "zdeconv"
  bottom: "imageconv14"
  top: "cond_pred_traj"
  eltwise_param{
    operation: PROD
  }
}

layer{
  name: "cond_pred_mag"
  type: "Eltwise"
  bottom: "magzdeconv"
  bottom: "imageconv14"
  top: "cond_pred_mag"
  eltwise_param{
    operation: PROD
  }
}

layer {
  name: "conv15"
  type: "Convolution"
  bottom: "cond_pred_traj"
  top: "conv15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "batchnorm15"
  type: "BatchNorm"
  bottom: "conv15"
  top: "conv15"
}

layer {
  name: "relu15"
  type: "ReLU"
  bottom: "conv15"
  top: "conv15"
}

layer {
  name: "conv16"
  type: "Convolution"
  bottom: "conv15"
  top: "conv16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "batchnorm16"
  type: "BatchNorm"
  bottom: "conv16"
  top: "conv16"
}


layer {
  name: "relu16"
  type: "ReLU"
  bottom: "conv16"
  top: "conv16"
}

layer {
  name: "conv17"
  type: "Convolution"
  bottom: "conv16"
  top: "conv17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "batchnorm17"
  type: "BatchNorm"
  bottom: "conv17"
  top: "conv17"
}


layer {
  name: "relu17"
  type: "ReLU"
  bottom: "conv17"
  top: "conv17"
}


layer {
  name: "conv18"
  type: "Convolution"
  bottom: "conv17"
  top: "conv18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "batchnorm18"
  type: "BatchNorm"
  bottom: "conv18"
  top: "conv18"
}


layer {
  name: "relu18"
  type: "ReLU"
  bottom: "conv18"
  top: "conv18"
}

layer {
  name: "conv19"
  type: "Convolution"
  bottom: "cond_pred_mag"
  top: "conv19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
        weight_filler {
          type: "xavier"
          std: 0.01
        }
  }
}

layer { 
  name: "batchnorm19"
  type: "BatchNorm"
  bottom: "conv19"
  top: "conv19"
}


layer {
  name: "relu19"
  type: "ReLU"
  bottom: "conv19"
  top: "conv19"
}

layer{
  name: "conv2reconst"
  type: "Convolution"
  bottom: "conv19"
  top: "conv2reconst"

  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    pad: 1
        weight_filler {
          type: "xavier"
          std: .001
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult:2
    decay_mult: 0
  }
}

layer{
  name: "conv1reconst"
  type: "Convolution"
  bottom: "conv18"
  top: "conv1reconst"

  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    pad: 1
        weight_filler {
          type: "xavier"
          std: .001
        }
    bias_filler {
      type: "constant"
      value: 0
    }
  }

  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult:2
    decay_mult: 0
  }
}

  layer {
    name: "reconstloss"
    type: "EuclideanLoss"
    bottom: "conv1reconst"
    bottom: "normtrajdata"
    top: "reconstloss"
    loss_weight: 0.016
  }

  layer {
    name: "magloss"
    type: "EuclideanLoss"
    bottom: "conv2reconst"
    bottom: "trajnorm"
    top: "magloss"
    loss_weight: 0.0016
  }

${cascade_short("deconv2","conv18", "imageconv4", 256, 2, 2, .004, 0.1, 1,5,2)}
${cascade_super_short("deconv3","deconv2reconst_inter_one", "imagenorm1", 256, 2, 1, .001, 0.1, 1,11,5)}

